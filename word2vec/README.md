# Word Embeddings
A simple introduction to word embeddings and Tomas Mikolov's [Word2Vec](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf). What will be covered:
1. Motivation for continuous representations of words
2. The skip-gram model for predicting context words
3. Basics of TensorFlow (before version 2.x)
4. TensorFlow's Embedding Projector to visualize learned embeddings
